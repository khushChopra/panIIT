{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.misc import imread\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file = 'training/training/54.png'\n",
    "img = cv2.imread(img_file, cv2.IMREAD_COLOR)\n",
    "\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "h, s, v = cv2.split(hsv)\n",
    "\n",
    "thresh2 = cv2.adaptiveThreshold(v, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "cv2.imshow('Image-thresh2', thresh2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file = 'training/training/54.png'\n",
    "img = cv2.imread(img_file, cv2.IMREAD_COLOR)\n",
    "\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "h, s, v = cv2.split(hsv)\n",
    "\n",
    "ret,thresh_img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (4,8))\n",
    "morph_img = cv2.morphologyEx(thresh_img, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "thresh2 = cv2.adaptiveThreshold(v, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "cv2.imshow('Image-thresh2', thresh2)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Image-thresh_img', thresh_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Image-morph_img', morph_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extractor\n",
    "def extract_features(image_path, vector_size=32):\n",
    "    image = imread(image_path, mode=\"RGB\")\n",
    "    try:\n",
    "        # Using KAZE, cause SIFT, ORB and other was moved to additional module\n",
    "        # which is adding addtional pain during install\n",
    "        alg = cv2.KAZE_create()\n",
    "        # Dinding image keypoints\n",
    "        kps = alg.detect(image)\n",
    "        # Getting first 32 of them. \n",
    "        # Number of keypoints is varies depend on image size and color pallet\n",
    "        # Sorting them based on keypoint response value(bigger is better)\n",
    "        kps = sorted(kps, key=lambda x: -x.response)[:vector_size]\n",
    "        # computing descriptors vector\n",
    "        kps, dsc = alg.compute(image, kps)\n",
    "        # Flatten all of them in one big vector - our feature vector\n",
    "        dsc = dsc.flatten()\n",
    "        # Making descriptor of same size\n",
    "        # Descriptor vector size is 64\n",
    "        needed_size = (vector_size * 64)\n",
    "        if dsc.size < needed_size:\n",
    "            # if we have less the 32 descriptors then just adding zeros at the\n",
    "            # end of our feature vector\n",
    "            dsc = np.concatenate([dsc, np.zeros(needed_size - dsc.size)])\n",
    "    except cv2.error as e:\n",
    "        print('Error: ', e)\n",
    "        return None\n",
    "\n",
    "    return dsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training/training/50.png\n",
      "50\n",
      "training/training/100.png\n",
      "100\n",
      "training/training/150.png\n",
      "150\n",
      "training/training/200.png\n",
      "200\n",
      "training/training/250.png\n",
      "250\n",
      "training/training/300.png\n",
      "300\n",
      "training/training/350.png\n",
      "350\n",
      "training/training/400.png\n",
      "400\n",
      "training/training/450.png\n",
      "450\n",
      "training/training/500.png\n",
      "500\n",
      "training/training/550.png\n",
      "550\n",
      "training/training/600.png\n",
      "600\n",
      "training/training/650.png\n",
      "650\n",
      "training/training/700.png\n",
      "700\n",
      "training/training/750.png\n",
      "750\n",
      "training/training/800.png\n",
      "800\n",
      "training/training/850.png\n",
      "850\n",
      "training/training/900.png\n",
      "900\n",
      "training/training/950.png\n",
      "950\n",
      "training/training/1000.png\n",
      "1000\n",
      "training/training/1050.png\n",
      "1050\n",
      "training/training/1100.png\n",
      "1100\n",
      "training/training/1150.png\n",
      "1150\n",
      "training/training/1200.png\n",
      "1200\n",
      "training/training/1250.png\n",
      "1250\n",
      "training/training/1300.png\n",
      "1300\n",
      "training/training/1350.png\n",
      "1350\n",
      "training/training/1400.png\n",
      "1400\n",
      "training/training/1450.png\n",
      "1450\n",
      "training/training/1500.png\n",
      "1500\n",
      "training/training/1550.png\n",
      "1550\n",
      "training/training/1600.png\n",
      "1600\n",
      "training/training/1650.png\n",
      "1650\n",
      "training/training/1700.png\n",
      "1700\n",
      "training/training/1750.png\n",
      "1750\n",
      "training/training/1800.png\n",
      "1800\n",
      "training/training/1850.png\n",
      "1850\n",
      "training/training/1900.png\n",
      "1900\n",
      "training/training/1950.png\n",
      "1950\n",
      "training/training/2000.png\n",
      "2000\n",
      "training/training/2050.png\n",
      "2050\n",
      "training/training/2100.png\n",
      "2100\n",
      "training/training/2150.png\n",
      "2150\n",
      "training/training/2200.png\n",
      "2200\n",
      "training/training/2250.png\n",
      "2250\n",
      "training/training/2300.png\n",
      "2300\n",
      "training/training/2350.png\n",
      "2350\n",
      "training/training/2400.png\n",
      "2400\n",
      "training/training/2450.png\n",
      "2450\n",
      "training/training/2500.png\n",
      "2500\n",
      "training/training/2550.png\n",
      "2550\n",
      "training/training/2600.png\n",
      "2600\n",
      "training/training/2650.png\n",
      "2650\n",
      "training/training/2700.png\n",
      "2700\n",
      "training/training/2750.png\n",
      "2750\n",
      "training/training/2800.png\n",
      "2800\n",
      "training/training/2850.png\n",
      "2850\n",
      "training/training/2900.png\n",
      "2900\n",
      "training/training/2950.png\n",
      "2950\n",
      "training/training/3000.png\n",
      "3000\n",
      "training/training/3050.png\n",
      "3050\n",
      "training/training/3100.png\n",
      "3100\n",
      "training/training/3150.png\n",
      "3150\n",
      "training/training/3200.png\n",
      "3200\n",
      "training/training/3250.png\n",
      "3250\n",
      "training/training/3300.png\n",
      "3300\n",
      "training/training/3350.png\n",
      "3350\n",
      "training/training/3400.png\n",
      "3400\n",
      "training/training/3450.png\n",
      "3450\n",
      "training/training/3500.png\n",
      "3500\n",
      "training/training/3550.png\n",
      "3550\n",
      "training/training/3600.png\n",
      "3600\n",
      "training/training/3650.png\n",
      "3650\n",
      "training/training/3700.png\n",
      "3700\n",
      "training/training/3750.png\n",
      "3750\n",
      "training/training/3800.png\n",
      "3800\n",
      "training/training/3850.png\n",
      "3850\n",
      "training/training/3900.png\n",
      "3900\n",
      "training/training/3950.png\n",
      "3950\n",
      "training/training/4000.png\n",
      "4000\n",
      "training/training/4050.png\n",
      "4050\n",
      "training/training/4100.png\n",
      "4100\n",
      "training/training/4150.png\n",
      "4150\n",
      "training/training/4200.png\n",
      "4200\n",
      "training/training/4250.png\n",
      "4250\n",
      "training/training/4300.png\n",
      "4300\n",
      "training/training/4350.png\n",
      "4350\n",
      "training/training/4400.png\n",
      "4400\n",
      "training/training/4450.png\n",
      "4450\n",
      "training/training/4500.png\n",
      "4500\n",
      "training/training/4550.png\n",
      "4550\n",
      "training/training/4600.png\n",
      "4600\n",
      "training/training/4650.png\n",
      "4650\n",
      "training/training/4700.png\n",
      "4700\n",
      "training/training/4750.png\n",
      "4750\n",
      "training/training/4800.png\n",
      "4800\n",
      "training/training/4850.png\n",
      "4850\n",
      "training/training/4900.png\n",
      "4900\n",
      "training/training/4950.png\n",
      "4950\n",
      "training/training/5000.png\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "data = np.zeros([5000,2048])\n",
    "i =1\n",
    "for file in os.listdir(\"training/training\"):\n",
    "    filename = \"training/training/\" + str(i)+\".png\"\n",
    "    data[i-1,:] = extract_features(filename)\n",
    "    if i%50==0:\n",
    "        print(filename)\n",
    "        print(i)\n",
    "    i+=1\n",
    "np.savetxt(\"foo.csv\", data, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.12067072 -0.07231914  0.13234359 ...  0.01751308  0.04705388\n",
      "  0.03011746]\n"
     ]
    }
   ],
   "source": [
    "print(extract_features('training/training/1.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.12067072 -0.07231914  0.13234359 ...  0.01751308  0.04705388\n",
      "   0.03011746]\n",
      " [-0.00133541 -0.00127059  0.00137381 ...  0.05396254  0.05238527\n",
      "   0.07762256]\n",
      " [ 0.01013919  0.00377335  0.02364538 ... -0.00503675  0.01514528\n",
      "   0.01720389]\n",
      " ...\n",
      " [ 0.04393062  0.09165015  0.17353173 ... -0.16218148  0.1668665\n",
      "   0.28226987]\n",
      " [ 0.00607947  0.00281522  0.10519034 ... -0.00939388  0.00598347\n",
      "   0.01256259]\n",
      " [ 0.05815609  0.0609915   0.06866132 ...  0.00138832  0.04483417\n",
      "   0.03366598]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 17s 1us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "#download mnist data and split into train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.obj\",\"rb\") as fp:\n",
    "    data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2048)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 2048)\n",
      "[[-1.20670721e-01 -7.23191425e-02  1.32343590e-01 ...  1.75130833e-02\n",
      "   4.70538847e-02  3.01174633e-02]\n",
      " [-1.33540586e-03 -1.27058628e-03  1.37380767e-03 ...  5.39625399e-02\n",
      "   5.23852743e-02  7.76225626e-02]\n",
      " [ 1.01391897e-02  3.77334771e-03  2.36453824e-02 ... -5.03674662e-03\n",
      "   1.51452832e-02  1.72038898e-02]\n",
      " ...\n",
      " [ 7.07504991e-03 -1.41255045e-02  4.95801345e-02 ... -7.24045749e-05\n",
      "   5.60668304e-05  7.39896423e-05]\n",
      " [ 1.29537797e-03  1.28684309e-03  6.04265835e-03 ...  7.69320934e-04\n",
      "   2.08866972e-04  7.69375823e-04]\n",
      " [-6.11201394e-03  1.85420532e-02  4.23159823e-02 ...  7.07729626e-03\n",
      "   1.02857826e-02  1.65955909e-02]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = np.split(data,[4000])\n",
    "print(X_train.shape)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.zeros([5000,1])\n",
    "with open(\"Y.obj\",\"rb\") as fp:\n",
    "    Y = pickle.load(fp)\\\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
